# Atividade: Tradução usando Transformer com Controle de Versões

## Pontos Positivos

- Introdução à Arquitetura Transformer: O tutorial oferece uma introdução à arquitetura transformer descrita no paper "Attention is All You Need".
- Flexibilidade: A implementação permite ajustes nos hiperparâmetros, possibilitando experimentos para otimizar o desempenho conforme os recursos disponíveis.

## Pontos Negativos

- Código do tutorial defasado e quebrado: O código está desatualizado. Em diversos momentos foram levantados erros durante a execução pelas bibliotecas Keras e TensorFlow, provavelmente devido a atualizações recentes que quebraram as APIs antigas.
- Documentação contém múltiplas versões do mesmo tutorial: A documentação do TensorFlow tem uma tradução em português, que foi usada para esse exercício. Porém também existe uma versão em inglês, mais atualizada (no entanto, ela também apresenta erros durante a execução).
- Tempo de Treinamento Elevado: O treinamento do modelo é demorado, especialmente em máquinas sem GPUs ou TPUs potentes.
- Complexidade do Código: A implementação é extensa e complexa, o que pode ser desafiador para iniciantes em aprendizado de máquina ou na biblioteca TensorFlow.
